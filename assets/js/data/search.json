[ { "title": "Machine Learning on a DMOJ problem: TLE18P1 - Hello, World!", "url": "/posts/tle18p1/", "categories": "Competitive Programming", "tags": "Algorithm", "date": "2021-08-21 16:00:00 -0400", "snippet": "IntroductionTLE 2018-19 P1 - Hello, World! is from an April Fools‚Äô Day contest; it‚Äôs not a serious competitive programming problem. If you take a look closely at the sample input, you might figure that the 2 means that there are two test cases and each case is a 28x28 grid of floats. The answers to the cases are 1 and 5 respectively. Now you might think of visualizing these grids:import matplotlib.pyplot as pltn = int(input())for _ in range(n):\ta = [list(map(float, input().split())) for i in range(28)]\tplt.imshow(a, cmap='binary')\tplt.show() Aha! They‚Äôre hand-drawn digits! So that‚Äôs what the chalkboard image was about.If you search up ‚Äúclassifying hand drawn digits,‚Äù you‚Äôll find that this is a classical machine learning problem. It‚Äôs called the ‚ÄúHello World‚Äù of ML.To solve this problem, we need a neural network to classify the input digits. The problem statement doesn‚Äôt say what accuracy is needed, but users commented that we need 95% accuracy to get full marks. If you aren‚Äôt familiar with neural networks, 3Blue1Brown does a good job explaining it here.How to solve it on DMOJWe can‚Äôt import an NN from a DMOJ submission, so we‚Äôll need to write our own neural network. The feed-forward needs to be written by hand, but we don‚Äôt have to write code to trains our model. We could train it elsewhere and export the edge weights, but I wanted to test my understanding and implementation skills, so I decided to do it from scratch. Well, not exactly from scratch‚Ä¶ I got my training data from MNIST.After extracting the gzip archives and converting the binary files to plaintext, we can train. My first (working) neural network was something like this:#include &lt;bits/stdc++.h&gt;#define all(x) (x).begin(), (x).end()#ifdef LOCALtemplate&lt;typename T&gt; void pr(T a){std::cerr&lt;&lt;a&lt;&lt;std::endl;}template&lt;typename T, typename... Args&gt; void pr(T a, Args... args){std::cerr&lt;&lt;a&lt;&lt;' ',pr(args...);}#elsetemplate&lt;typename... Args&gt; void pr(Args... args){}#endifusing namespace std;using vd = vector&lt;double&gt;;using vvd = vector&lt;vd&gt;;using vvvd = vector&lt;vvd&gt;;mt19937_64 g(0);double randf(double l, double r){return uniform_real_distribution&lt;double&gt;(l, r)(g);}struct neural_network{\tvvvd edge_weight;\tvector&lt;int&gt; layer;\tint layercnt;\tdouble const learning_rate = 0.01;\tdouble sigmoid(double x){\t\treturn 1/(1 + exp(-x));\t}\tdouble derivative_sigmoid(double x){\t\treturn sigmoid(x)*(1-sigmoid(x));\t}\tdouble cost(vd answer, vd output){\t\tdouble x = 0;\t\tfor(int i = 0; i &lt; size(answer); i++){\t\t\tx += (answer[i]-output[i])*(answer[i]-output[i]);\t\t}\t\treturn x;\t}\tbool correct(vd answer, vd output){\t\tint i = max_element(all(answer))-answer.begin();\t\tint j = max_element(all(output))-output.begin();\t\treturn i == j;\t}\tvoid init(vector&lt;int&gt; _l){\t\tfor(auto &amp;i: _l)\t\t\ti++;\t\tlayer = _l;\t\tlayercnt = size(layer);\t\t\t\tedge_weight.resize(layercnt-1);\t\tfor(int i = 0; i &lt; layercnt-1; i++){\t\t\t\t\t\tedge_weight[i].resize(layer[i]);\t\t\tfor(int j = 0; j &lt; layer[i]; j++){\t\t\t\tedge_weight[i][j].resize(layer[i+1]);\t\t\t\t\t\t\t\tfor(int k = 0; k &lt; layer[i+1]; k++){\t\t\t\t\tif(!j)\t\t\t\t\t\tedge_weight[i][j][k] = 1;\t\t\t\t\telse if(!k)\t\t\t\t\t\tedge_weight[i][j][k] = 0;\t\t\t\t\telse\t\t\t\t\t\tedge_weight[i][j][k] = randf(-.5, .5);\t\t\t\t}\t\t\t}\t\t}\t}\tpair&lt;vvd, vvd&gt; run(vector&lt;double&gt; input){\t\tvvd values(layercnt), values_after_sigmoid(layercnt);\t\tinput.insert(input.begin(), 1); // bias\t\tfor(int i = 0; i &lt; layercnt; i++)\t\t\tvalues[i].resize(layer[i]);\t\tassert(size(input) == layer[0]);\t\tvalues[0] = input;\t\tvalues_after_sigmoid = values;\t\t\t\tfor(int i = 0; i &lt; layercnt; i++){\t\t\tfor(int j = 0; j &lt; layer[i]; j++){\t\t\t\tif(i == 0) values_after_sigmoid[i][j] = values[i][j]/254;\t\t\t\telse values_after_sigmoid[i][j] = sigmoid(values[i][j]);\t\t\t\tif(i+1 &lt; layercnt){\t\t\t\t\tfor(int k = 0; k &lt; layer[i+1]; k++){\t\t\t\t\t\tvalues[i+1][k] += values_after_sigmoid[i][j]*edge_weight[i][j][k];\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}\t\treturn {values, values_after_sigmoid};\t}\tvoid train(vector&lt;pair&lt;vd, vd&gt;&gt; tests){\t\tvvvd gradient;\t\tgradient.resize(layercnt-1);\t\tfor(int i = 0; i &lt; layercnt-1; i++){\t\t\tgradient[i].resize(layer[i]);\t\t\tfor(auto &amp;j: gradient[i]){\t\t\t\tj.resize(layer[i+1]);\t\t\t}\t\t}\t\tfor(auto [input, answer]: tests){\t\t\tauto [values, values_after_sigmoid] = run(input);\t\t\tinput.insert(input.begin(), 1);\t\t\tanswer.insert(answer.begin(), 1);\t\t\tvvd node_derivatives;\t\t\tnode_derivatives.resize(layercnt);\t\t\tfor(int i = 0; i &lt; layercnt; i++){\t\t\t\tnode_derivatives[i].resize(layer[i]);\t\t\t}\t\t\tfor(int j = 0; j &lt; layer[layercnt-1]; j++){\t\t\t\tnode_derivatives[layercnt-1][j] = 2*(values_after_sigmoid[layercnt-1][j] - answer[j]);\t\t\t}\t\t\tfor(int i = layercnt-1; i &gt; 0; i--){\t\t\t\tfor(int k = 0; k &lt; layer[i]; k++){\t\t\t\t\tdouble d = derivative_sigmoid(values[i][k])*node_derivatives[i][k];\t\t\t\t\tfor(int j = 0; j &lt; layer[i-1]; j++){\t\t\t\t\t\tif(k == 0) continue;\t\t\t\t\t\tgradient[i-1][j][k] += d*values_after_sigmoid[i-1][j];\t\t\t\t\t\tnode_derivatives[i-1][j] += d*edge_weight[i-1][j][k];\t\t\t\t\t}\t\t\t\t}\t\t\t}\t\t}\t\tint testcnt = size(tests);\t\t\tfor(int i = 0; i &lt; layercnt-1; i++){\t\t\tfor(int j = 0; j &lt; layer[i]; j++){\t\t\t\tfor(int k = 0; k &lt; layer[i+1]; k++){\t\t\t\t\tif(k == 0) continue;\t\t\t\t\tedge_weight[i][j][k] -= gradient[i][j][k]*learning_rate/testcnt;\t\t\t\t}\t\t\t}\t\t}\t}};I treated the 0th node in each layer as a dummy source for biases. All edges going into dummy nodes had a weight of 0 except for the one coming from the bias of the previous row, which had a value of 1. I also added a 0th dummy node in the input layer that always had a value of 1, so that it would feed all the biases.DMOJ‚Äôs source code character limitIt took a lot of debugging to get my model to work. I then had to face the 64k character limit on DMOJ. My original neural network needed 223k characters to store its edges. I decided to do a 5x5 convolution and 2x2 max pooling in order to shrink my input layer from 28x28 to 12x12 nodes. My new model only needs 45k characters. Plus, it also takes less time to train.Another way to get around the character limit is to do data compression.vvd convolution(vvd pre, int sz){\tint n = size(pre);\tvvd cur(n-sz+1, vd(n-sz+1));\tfor(int i = 0; i &lt; n-sz+1; i++){\t\tfor(int j = 0; j &lt; n-sz+1; j++){\t\t\tfor(int x = 0; x &lt; sz; x++){\t\t\t\tfor(int y = 0; y &lt; sz; y++){\t\t\t\t\tcur[i][j] += pre[i+x][j+y]/sz/sz;\t\t\t\t}\t\t\t}\t\t}\t}\treturn cur;}vvd max_pooling(vvd pre, int k){\tint n = size(pre);\tassert(n%k == 0);\tint sz = n/k;\tvvd cur(sz, vd(sz));\tfor(int i = 0; i &lt; sz; i++){\t\tfor(int j = 0; j &lt; sz; j++){\t\t\tfor(int x = 0; x &lt; k; x++){\t\t\t\tfor(int y = 0; y &lt; k; y++){\t\t\t\t\tcur[i][j] = max(cur[i][j], pre[i*k+x][j*k+y]);\t\t\t\t}\t\t\t}\t\t}\t}\treturn cur;}vd flatten(vvd pre){\tvd cur;\tfor(auto i: pre){\t\tfor(auto j: i){\t\t\tcur.push_back(j);\t\t}\t}\treturn cur;}pair&lt;vd, vd&gt; read_and_convolute(ifstream &amp;in){\tvd ans(10);\tint x; in&gt;&gt;x;\tans[x] = 1;\tvvd cur(28, vd(28));\tfor(auto &amp;i: cur){\t\tfor(auto &amp;j: i){\t\t\tin&gt;&gt;j;\t\t}\t}\tcur = convolution(cur, 5);\tcur = max_pooling(cur, 2);\treturn {ans, flatten(cur)};}I could now create a random model and export it to a file.void create_nn(){\tneural_network nn;\tnn.init({12*12, 30, 10});\tnn.export_edges(1);}And I repeatedly improved my model with run():void run(){\tvector&lt;pair&lt;vd, vd&gt;&gt; train_set, test_set, tmp;\t// 60000 in train set\t// 10000 in test set\tifstream train_input(\"mnist_train.txt\");\ttrain_input.exceptions(ifstream::failbit | ifstream::badbit);\tfor(int t = 0; t &lt; 60000; t++){\t\tauto [answer, input] = read_and_convolute(train_input);\t\ttrain_set.push_back({input, answer});\t}\ttrain_input.close();\tneural_network nn;\tnn.import_edges();\t\tfor(int i = 0; i &lt; 20000000; i++){\t\tif(i%100000 == 0){\t\t\tcerr&lt;&lt;\"i \"&lt;&lt;i&lt;&lt;endl;\t\t}\t\tint j = randint(0, (int)size(train_set)-1);\t\ttmp = {train_set[j]};\t\tnn.train(tmp);\t}\t\tnn.export_edges(1);}Each time it finished training, I made a DMOJ submission to see what my accuracy was. I spent about one hour training in total.It took me a long time to come up with workable parameters. I settled on 0.01 as my learning rate. I tried doing k-fold cross-validation and training in epochs (with the entire test set), but those methods trained slower than my method of randomly picking 20,000,000 images to use.There‚Äôs a lot more I can do to optimize my code, but the asymptotically worst parts, namely the feed-forward and backpropagation, were good enough.ConclusionBy coding up an NN by hand, I found gaps in my understanding. This exercise got me to think through every step of my algorithm and how I should tweak my constants. There‚Äôs still more I‚Äôd like to explore. For example, when I initially used ReLU, I struggled to address exploding gradients. Once again, I obviously won‚Äôt write scrappy NNs by hand in the future; this was just a exercise. I hope to bring you more fun content in the future. Bye! üëã" }, { "title": "Comparing 2N and 4N-sized recursive segment trees", "url": "/posts/segment-tree/", "categories": "Competitive Programming", "tags": "Algorithm, Investigation", "date": "2021-07-08 10:32:48 -0400", "snippet": "IntroductionWhen you implement a recursive segment tree, it‚Äôs better to store segment tree nodes in an array or vector than it is to create a new object for every node one by one. This reduces the time it takes to create the nodes and it improves caching since the nodes are in a contiguous chunk of memory.4N implementationIf you have vector&lt;node&gt; nodes, you might make nodes[1] the root node and for every node x, make its left and right children 2x and 2x+1 respectively. Another way might be to have node[0] as the root and have 2x+1 and 2x+2 as the children of node x.Either way of indexing uses $2N-1$ nodes when the segment tree is a perfect binary tree, which happens when $N$ is a power of $2$. Otherwise, we should give the tree $2 \\cdot 2^{\\left \\lceil \\log_2 N \\right \\rceil}$ nodes to be safe. This is because even though only $2N-1$ nodes are actually used, some indices of nodes are skipped. For convenience, we can bound this by $4N$. Our code could look something like this:#define nm ((nl+nr)/2)int SZ = 10; // or whatever number you needstruct node{\t// content}; vector&lt;node&gt; nodes(4*SZ);// each node nodes[rt] covers the interval [nl, nr]void build(int nl = 0, int nr = SZ-1, int rt = 1){\tif(nl == nr){\t\t// initialize nodes[rt]\t\treturn;\t}\tbuild(nl, nm, rt&lt;&lt;1);\tbuild(nm+1, nr, rt&lt;&lt;1|1);}2N implementationsOne way to create a recursive segment tree with exactly $2n-1$ nodes is to create new nodes as we need them. As mentioned at the start, this performs far worse than the implementation with a vector of size $4n$. However, it will help us reach a solution that uses $2n$ memory. The code might look something like this:#define nm ((nl+nr)/2)struct node{\t// content\tnode *lc, *rc;\t// lc is pointer to left child, rc is pointer to right child};// returns a pointer to the node that covers the interval [nl, nr]node* build(int nl, int nr){\tnode *cur = new node();\tif(nl == nr) return cur;\tcur-&gt;lc = build(nl, nm);\tcur-&gt;rc = build(nm+1, nr);\treturn cur;}We could speed this up by creating all our nodes in advance like so:#define nm ((nl+nr)/2)int SZ = 10, ptr = 0;struct node{\t// content\tint lc, rc;\t// left child is nodes[lc]\t// right child is nodes[rc]}; vector&lt;node&gt; nodes(SZ*2-1);int build(int nl, int nr){\tint cur = ptr++;\tpr(nl, nr, cur);\tif(nl == nr){\t\t// initialize nodes[ptr]\t\treturn cur;\t}\tnodes[cur].lc = build(nl, nm);\tnodes[cur].rc = build(nm+1, nr);\treturn cur;}int main(){\tbuild(0, 5);}Notice that when we are at node cur, we will assign the indices of nodes first to the left subtree, then to the right subtree. Since our recursive algorithm uses $2N‚Äô-1$ nodes to cover an interval of size $N‚Äô$, we will give the left subtree the next $2(nm-nl+1)$ nodes and give the following ones to the right subtree. This is almost the same as our original code, the only difference being how we index our nodes. This speeds up our code and uses less memory than the previous 2N implementation since we don‚Äôt need to store and check what our left and right children are.#define nm ((nl+nr)/2)int SZ = 10;struct node{\t// content}; vector&lt;node&gt; nodes(2*SZ-1);void build(int nl = 0, int nr = SZ-1, int rt = 0){\tpr(nl, nr, rt);\tif(nl == nr){\t\t// initialize nodes[rt]\t\treturn;\t}\tbuild(nl, nm, rt+1);\tbuild(nm+1, nr, rt+(nm-nl+1)*2);}BenchmarksThe question remains: is this faster than our original 4N implementation? No. In practice, the 4N implementation is faster. Testcase 2N Segment Tree 4N Segment Tree example_00 1 ms / 0.70 MB 1 ms / 0.61 MB max_random_00 666 ms / 18.33 MB 653 ms / 19.11 MB max_random_01 667 ms / 18.34 MB 649 ms / 19.09 MB max_random_02 658 ms / 18.33 MB 654 ms / 19.09 MB max_random_03 660 ms / 18.34 MB 652 ms / 19.08 MB max_random_04 662 ms / 18.34 MB 653 ms / 19.09 MB random_00 519 ms / 14.46 MB 526 ms / 18.59 MB random_01 562 ms / 16.73 MB 560 ms / 18.71 MB random_02 274 ms / 4.10 MB 281 ms / 4.46 MB random_03 201 ms / 13.85 MB 203 ms / 16.84 MB random_04 198 ms / 9.59 MB 199 ms / 17.21 MB small_00 1 ms / 0.71 MB 1 ms / 0.71 MB small_01 1 ms / 0.71 MB 1 ms / 0.71 MB small_02 1 ms / 0.62 MB 1 ms / 0.71 MB small_03 1 ms / 0.71 MB 1 ms / 0.71 MB small_04 1 ms / 0.71 MB 1 ms / 0.71 MB We already knew that we save up to half our memory by switching to the 2N implementation. Here is a graph of how large our vector nodes actually needs to be for each of our implementations. For the 4N implementation, our allocation of $2 \\cdot 2^{\\left \\lceil \\log_2 N \\right \\rceil}$ nodes was only an upper bound, albeit a reasonable one. It‚Äôs satisfying to see the 4N graph turn into a staircase as N gets large. Memory Usage graph from 1 to 100 Memory Usage Graph from 1 to 1,000,000 ConclusionsThe 2N implementation uses less memory and the 4N implementation is a little faster. These small differences will not matter if the problems you are solving have reasonable time and memory limits.Now of course, we could just use iterative segment trees. I guess this blog post was useless (perhaps I should have discussed ‚Äúwalking‚Äù on an iterative segment tree instead). ‚òπÔ∏èI will soon be investigating the feasibility of using ‚Äúfat nodes‚Äù in segment trees. Stay tuned! üìª" }, { "title": "My (ICPC) Codebook", "url": "/posts/codebook/", "categories": "Competitive Programming", "tags": "", "date": "2021-07-05 17:43:22 -0400", "snippet": "In the ICPC (International Collegiate Programming Contest), each team is allowed to bring up to 25 pages of printed material. There are many great codebooks out there such as KACTL, but I prefer to write templates by myself. I am currently using verification-helper to manage my codebook. What makes verification-helper so useful is that it lets you create tests for your templates, which get run on Atcoder and Library Checker problems. It also has an oj-bundle script that merges all the templates you‚Äôve used into your solution file.The only missing feature is an ‚Äúexport to pdf‚Äù feature. This doesn‚Äôt matter so long as ICPC contest are online, but I‚Äôll have to worry about this in the future." }, { "title": "CCO 2020", "url": "/posts/cco-2020/", "categories": "Contests", "tags": "CCO", "date": "2021-07-04 11:56:10 -0400", "snippet": "My ExperienceNote: I am writing this blog in June 2021, after the 2021 (not 2020) CCO.2020 was my first time at the Canadian Computing Olympiad (CCO). The top 25 or so high school students from the (open) Canadian Computing Contest Senior Division (CCC Senior) are invited to the CCO, which serves as a Team Selection Test (TST) for the Canadian International Olympiad in Informatics (IOI) team of four. It normally runs for a week in May at the University of Waterloo. It was held online this year, which meant that I missed out on a lot of fun.I had come out of the CCC with a nice lead of 15 points over many contestants. I believe that I had gotten lucky by not overestimating the difficulty of the last problem on the CCC. I did not expect to make the IOI team since there were so many contestants better than me. If I recall correctly, I expected to place around 10th.My mock contest sessions had taught me how challenging and mentally draining the CCO would be. I did not expect the two contest days to be pleasant. In fact, I was surprised when the day 1 contest turned out to be easier than I expected. After day 1, I saw that I was tied with Andrew Dong at 4th place (scoreboard). I couldn‚Äôt believe that I had a real chance at making the IOI team!This hope was lost on day 2 when I scored a meager 3/75. I spent most of my time grinding data structures on P5 and did nothing to get any partial marks. This was a big mistake, seeing that Andrew Dong tied for 4th place by getting a few partial marks on every problem. On day 2, I suffered from the phenomenon of ‚Äútunnel vision,‚Äù which meant that I was so fixated on one idea that I ignored everything else. In addition, my contest preparation consisted of mostly Codeforces rounds and not enough OI (informatics olympiad) material. This problem-solving focus worked well for a simpler contest like the CCC, but not for the CCO.I ended up in 9th place, which I was happy with. I did not regret missing an opportunity to qualify for the IOI team since I had no such expectation in the first place. Plus, I still had one more opportunity the following year. I took a one-week break from programming following the CCO. Afterwards, I practised a lot of implementation-heavy OI problems. I was already getting ready for next year‚Äôs contest.SolutionsHere‚Äôs what you have all been waiting for.My code is available here. Remember not to copy and paste code on DM::OJ.Day 1 Problem 1 - A Game with GrundyFind each friend‚Äôs vision‚Äôs intersections with the line $y = Y$. If the left intersection point is at $(x_1, Y)$ and the right one is at $(x_2, Y)$, we can add two update operations: +1 at $\\lceil x_1 \\rceil$ and -1 at $\\lfloor x_2 \\rfloor +1$. Finally, line sweep over the updates from left to right.Time complexity: $\\mathcal{O}(N \\log N)$.Number of solves1: 18/20.Day 1 Problem 2 - Exercise DeadlinesThe key to solving this problem is coming up with a greedy strategy to order the exercises. First, we see that on day $N$, we can only complete the exercises that are due on day $N$. If any such exercises exist, we can greedily take the rightmost one since it requires the least amount of swaps to move to day $N$. On day $N-1$, we can complete the exercises with deadlines of day $N-1$ or $N$. We can once again greedily take the rightmost such exercise. Our greedy algorithm is to loop the days from $N$ to $1$ and on each day, take the rightmost task that is due on or after the current day. To get the total number of swaps, also known as inversions, we will use a data structure to assist us. This is guaranteed to give the minimum number of swaps. I will prove by contradiction that this is the case.On day $i$, our greedy solution takes the exercise at index $r$. Suppose that there is an exercise at index $l$ ($l &lt; r$) which we should take instead to get a better answer. Let $j$ be the day on which index $l$ is taken in our greedy strategy. Now let $f(x, y) = |x-y|$, which represents the cost of moving the exercise currently at day $x$ to day $y$. We find that this function satisfies the quadrangle inequality, which is $f(l, j) + f(r, i) \\le f(l, i) + f(r, j)$ given that $l \\le r \\le j \\le i$ (we know that $r \\le j$ since we can not take an exercise past its due date). The quadrangle inequality is enough to show that our algorithm is correct since it contradicts our assumption that there was a better option than our greedy algorithm.If on any day $i$, there is no exercise we can complete, then we will need to complete the remaining $i$ exercises in $i-1$ days, which is impossible.Time Complexity: $\\mathcal{O}(N \\log N)$.Number of solves: 9/20.Day 1 Problem 3 - Mountains and Valleys (Half Editorial)I found this to be the hardest problem of the contest.If there are no mountainous trails, then we are left with a tree and our answer is $2(N-1) - (\\text{the diameter of the tree})$.In subtask 3, where the mountainous paths weights are restricted to $w_i \\ge \\lceil \\frac{N}{2} \\rceil$, we can show that the optimal path does not take any mountainous edge. Taking a mountainous edge from $a$ to $b$ with distance $w$ improves our answer by at most $w - \\text{distance}(a, b) \\ge \\left\\lceil \\frac{N}{2} \\right\\rceil - \\text{distance}(a, b)$. We need $\\text{distance}(a, b) \\ge \\left\\lceil \\frac{N}{2} \\right\\rceil$ for the mountainous path to be worth taking. If this were true, it means that the diameter is at least $\\left\\lceil \\frac{N}{2} \\right\\rceil$, which in turn means that our original answer of $2(N-1) - (\\text{the diameter of the tree})$ was at most $2(N-1) - \\left\\lceil \\frac{N}{2} \\right\\rceil$. Our new answer is at least $N-2 + \\left\\lceil \\frac{N}{2} \\right\\rceil$, since we need to take at least $N-1$ edges in order to visit $n$ nodes and one of those edges is a mountainous one. If the new answer is indeed better than the old one, then we should have:\\[\\newcommand\\floor[1]{\\left\\lfloor#1\\right\\rfloor}\\newcommand\\ceil[1]{\\left\\lceil#1\\right\\rceil}\\begin{align*}N-2 + \\ceil{\\frac{N}{2}} &amp;&lt; 2(N-1) - \\ceil{\\frac{N}{2}} \\\\N-2 + \\ceil{\\frac{N}{2}} &amp;&lt; 2N-2 - \\left(N + \\ceil{\\frac{N}{2} - N} \\right) \\\\N-2 + \\ceil{\\frac{N}{2}} &amp;&lt; N-2 - \\ceil{\\frac{N}{2} - N} \\\\\\ceil{\\frac{N}{2}} &amp;&lt; - \\ceil{\\frac{N}{2} - N} \\\\\\ceil{\\frac{N}{2}} &amp;&lt; - \\left( -\\floor{\\frac{N}{2}} \\right) \\\\\\ceil{\\frac{N}{2}} &amp;&lt; \\floor{\\frac{N}{2}} .\\\\\\end{align*}\\]This is impossible, which contradicts our assumption that there was a case where a mountainous edge was needed in the optimal path. Therefore the answer in subtask 3 is always $2(N-1) - (\\text{the diameter of the tree})$.To solve the full problem, we can use similar reasoning to prove that we will need to take at most one mountainous edge. The dynamic programming involved is very cancerous and I had to do a decent amount of constant optimization to get my solution to pass. My AC solution on DM::OJ is 287 lines long and passes right under the time limit. I wish you luck if you are attempting to solve this problem.Time Complexity: $\\mathcal{O}((N + M) \\log N)$ with a large constant factor. The $\\log N$ comes from binary lifting.Number of solves: 1/20.P.S. There also exists a (slower?) centroid decomposition solution that I do not understand at all.Day 2 Problem 1 (Problem 4) - Travelling SalespersonHere is a solution that visits exactly $2N$ buildings. We can arbitrarily choose a starting building and, for every building connected to it with a red road, travel there and back. Then, for every building that is connected to the starting building with a blue road, we also go there and back. How many points will this yield? We can submit this code to find that we get exactly 8 points, which means that $2N$ is twice the length of the optimal route and that the optimal route‚Äôs length is exactly $N$.Consider a valid path, $b$, of length $k$ ($ b_0, b_1, ‚Ä¶, b_{k-2}, b_{k-1}$). Without loss of generality, the path starts off with some red roads, then switches to using blue roads. When we want to add a new building $c$ to the path, we will try connecting it to either $b_0$ or $b_{k-1}$. If the road $(b_0, c)$ is red, then we can add $c$ to the start of the path. If the road ($b_{k-1}, c)$ is blue, then we can add $c$ to the end of the path. If neither of these are true, we consider the colour of road $(b_0, b_{k-1})$. If it is blue, then we can change our path into $b_1, ‚Ä¶, b_{k-2}, b_{k-1}, b_0, c$. If it is red, then we can change our path to be $c, b_{k-1}, b_0, b_1, ‚Ä¶, b_{k-2}$. We can keep doing this until we get a path of length $N$ containing every building exactly once.Time Complexity: $\\mathcal{O}(N^2)$ (the slowest part is reading the input).Number of solves: 1/20.Day 2 Problem 2 (Problem 5) - Interval CollectionLet $minr_i$ be equal to the leftmost right endpoint of a segment whose left endpoint is at $i$. If no such right endpoint exists, then $minr_i = \\infty$. Likewise, let $maxl_i$ be equal to the rightmost left endpoint of a segment whose right endpoint is at $i$. If no such left endpoint exists, then $maxl_i = -\\infty$. We will make a segment tree over each of these lists. Let $L(l, r)$ equal the maximum $maxl_i$ in the range $l \\le i \\le r$ and let $R(l, r)$ equal the minimum $minr_i$ in the range $l \\le i \\le r$.We will be solving this problem online and updating the segment tree as we add or remove new segments. At each point in time, we will first try to take a set of segments that do not intersect. We can check if any such segments exist by querying the global $minr_g$ and $maxl_g$. When the minimum right endpoint is less than or equal to the highest left endpoint, there exists at least one way to take a set of non-overlapping/disjoint segments: any segment with its right endpoint at $minr_g$ and any segment with its left endpoint at $maxl_g$ will work (I do not yet claim that this is optimal).How do we find the optimal set of disjoint segments to take? In a set of two disjoint segments ${[l_1, r_1], [l_2, r_2]}, r_1 \\le l_2$, the length is $r_2-l_1$. Adding another segment will never decrease the length of the least enclosing interval, so we don‚Äôt need to consider sets with more than two segments. First we will try to solve the problem if we never need to remove segments. In this case, after adding a segment $[l, r]$, the only new possible sets we need to consider to make our answer better are the ones with least enclosing intervals of $[l, R(r, \\infty)]$ and $[L(-\\infty, l), r]$. We will update our current answer if either of these is better. Our answer will only get better as we add more segments. To extend our solution to allow for removal of segments, we can ‚Äúcombine‚Äù pairs of intervals as we merge segment tree nodes. At a leaf node corresponding to location $i$, our answer is $ans_\\text{node} = minr_i - maxl_i$. At other segment tree nodes, the answer for the whole node is $ans_\\text{node} = \\min(ans_\\text{left child}, ans_\\text{right child}, minr_\\text{right child} - maxl_\\text{left child})$. Our final answer is $ans_\\text{root node}$. This merging works since we are forcing left segments to end before right segments start.When there are no sets of disjoint segments, we are told to minimize the greatest common interval. This common interval will be $[maxl_g, minr_g]$. This means that we take a segment with the least right endpoint and a segment with the highest left endpoint. These two intervals are $[maxl_{minr_g}, minr_g]$ and $[maxl_g, minr_{maxl_g}]$. Note that we only take one segment when these are the same because the greatest common interval is just the single segment.Time Complexity: $\\mathcal{O}(N \\log N)$.Number of solves: 1/20.Day 2 Problem 3 (Problem 6) - Shopping PlansThis problem uses a technique called fracturing search. It‚Äôs very similar to using a modified Dijkstra‚Äôs algorithm to find the $K^\\text{th}$ shortest path, but the problem with a naive implementation is that the number of states and transitions we need might be huge. We want an $\\mathcal{O}(1)$ transition and $\\mathcal{O}(K)$ states.First let‚Äôs assume that there is only one type of item. We sort all the items in non-decreasing order (of cost) and add the first $x_0$ of them to our base cost. We will call this the base state: the one that costs the least, with a cost of our ‚Äúbase cost‚Äù variable. Imagine that we have pointers (like arrows) pointing at each of the first $x_0$ items, indicating which ones we are taking. The way we will get to an arbitrary state is by first moving the rightmost pointer to the right, one step at a time until it reaches the rightmost item we need. We will never touch this pointer again. Let‚Äôs say that we ‚Äúglue it down.‚Äù Now we begin moving the second rightmost pointer up until it reaches the second rightmost item we plan on taking and glue it down. Repeat this for every pointer we have. Notice that we never have two pointers point at the same item and we never ‚Äújump‚Äù a pointer over another one as it moves right. We may also add new pointers if we need to add more pointers to reach this arbitrary state. We will add additional pointers pointing to the leftmost item only when it is not already being pointed at.We can let our state be $(j, cnt, maxr)$. $j$ means that the rightmost pointer that hasn‚Äôt been glued down is at index $j$ from the left. When $cnt &lt; x_0$, $cnt$ means how many pointers have been moved from their original spots. When $cnt \\ge x_0$, $cnt$ means how many pointers we currently have in our state. $maxr$ is the index of the leftmost pointer that has been glued down. This is needed so that we don‚Äôt move future pointers at or beyond this point.The only transitions we need are: Moving $j$ right by one. Gluing down the current $j$ and moving the next pointer (that is among one of the original $x_0$ ones) to the right by one. Creating a new pointer that points to the first item.Notice that every state corresponds to a unique set of choices (a state may correctly appear multiple times, since there may be multiple ways to reach a state). We have an $\\mathcal{O}(1)$ transition and we only need to visit exactly $K$ (not necessarily unique) states.To extend our solution to work with multiple rows, we can add an $i$ to our state, representing which row we‚Äôre currently processing. We will process the rows from top to bottom and add transitions to go from the current state $(i, j, cnt, maxr)$ to a state in the following row. When we do this, we need to make sure that the new state represents a different set of pointers, otherwise our algorithm would not work. We can do this by forcing ourselves to, in addition to going to the next row, moving the rightmost pointer on the next row to the right by one. Let $base(i)$ denote the ‚Äúbase state‚Äù of row $i$, that which has the last cost. Let $right(i)$ denote the base state but with the rightmost pointer moved right by one. What if we want to skip a row? We can create a transition from the $right(i)$ to $right(i+1)$, but also subtracts the cost difference between $right(i)$ and $base(i)$. This essentially skips row $i$ without moving any pointers in its row. To ensure that we visit our states in non-decreasing order of cost, we need to first sort the rows based on their ${x_i+1}^\\text{th}$ elements. Watch out for numerous edge cases when implementing this.Time Complexity: $\\mathcal{O}(N \\log N + M \\log M + K \\log K)$.Number of solves: 0/20.Closing remarksThis blog post took me forever to write. At least I learned a few things along the way. For example, I found out that one of my passing solutions to P5 ran in $\\mathcal{O}(N^2 \\log N)$ rather than the intended $\\mathcal{O}(N \\log N)$.Despite all the time it took to create this post, I plan on continuing with these blogs as I have plenty of time this summer. See you soon! üôÇFOOTNOTES Data not available for 4 people.¬†&#8617; " }, { "title": "My Contest History", "url": "/posts/contest-history/", "categories": "Contests", "tags": "", "date": "2021-07-01 09:25:00 -0400", "snippet": "My Online RatingsRating badges are available here. Pull requests to add more sites are welcomed.My Contest History (only major contest are listed): Code Jam 2022 Round 3 580th place Code Jam 2022 Round 2 599th place Code Jam 2022 Round 1B 101st place Meta Hacker Cup 2021 Round 3 207th place Meta Hacker Cup 2021 Round 2 56th place Montgomery Blair Informatics Tournament 5th place team Canadian Computing Olympiad (CCO) 2021 6th place, silver medalist Canadian Computing Competition (CCC) 2021 - Senior Division 1st place, invitation to the Canadian Computing Olympiad Winter 2021 ICPC-style Waterloo Local Contest 11th place Quora Programming Challenge 2021 Division 1 102th place Fall 2020 ICPC-style Waterloo Local Contest 7th place Kick Start 2020 Round G 47th place Kick Start 2020 Round F 178th place Facebook Hacker Cup 2020 Round 2 475th place Facebook Hacker Cup 2020 Round 1 279th place Facebook Hacker Cup 2020 Qualification Round 430th place Spring 2020 Waterloo Local Contest 13th place Code Jam 2020 Round 3 309th place Canadian Computing Olympiad (CCO) 2020 9th place, silver medalist Code Jam 2020 Round 2 803rd place Code Jam 2020 Round 1B 601st place Kick Start 2020 Round B 241st place USACO 2020 US Open Contest - Platinum Division 95th place USACO 2020 February Contest - Platinum Division 187th place Canadian Computing Competition (CCC) 2020 - Senior Division 1th place, invitation to the Canadian Computing Olympiad Olympiads Computing Competition 2019 - Gold Division 1th place Triway Cup 2019 - Senior Division 5th place Don Mills Programming Gala 2019 - Silver Division 2nd place Canadian Computing Competition (CCC) 2019 - Senior Division 104th place " }, { "title": "What is this?", "url": "/posts/what-is-this/", "categories": "", "tags": "", "date": "2021-06-27 12:41:00 -0400", "snippet": "Back in February 2020, I wrote the Canadian Computing Competition (CCC) and received a perfect score. My programming teacher suggested that his students write a blog on the contest. A month later, when Canada entered Coronoavirus lockdown, I scraped together a website on which to publish my CCC 2020 blog. There was so much cool stuff about programming I wanted to share, so I thought that I would quickly fill up my blog. However, I never had to motivation to package up my ideas into presentable content.Recently, I found out about Jekyll. I much prefer writing in Markdown over HTML. Plus, this Jekyll site has a ton of features. I hope that now, I‚Äôll write more to share my experiences.I‚Äôve moved over my old CCC 2020 blog and I plan on writing about topics such as recent contests, algorithm tutorials, and even non-technical subjects such as my programming mindset.Thanks for reading this far and I hope I‚Äôll have a lot more content up by the time you read this. üëã" }, { "title": "CCC 2020", "url": "/posts/ccc-2020/", "categories": "Contests", "tags": "CCC", "date": "2020-03-25 10:00:00 -0400", "snippet": "This year‚Äôs Canadian Computing Competition was held on February 12, 2020. Here I will dissect the results of the Senior Division contest.Contest Analysis CCC 2019 CCC 2020 This year‚Äôs S1 and S2 average scores were significantly lower than last year‚Äôs. This is because the difficulty of these early problems has increased. S3 had a higher average score but a lower non-zero average score. I‚Äôm not sure what to make of this, but know that the nature of this year‚Äôs S3 is different. Last year‚Äôs S3 tested the contestant‚Äôs ability to come up with an ‚Äúad hoc‚Äù solution and then debug it. This is in contrast to this year‚Äôs S3 which (straightforwardly) tested for knowledge of string algorithms. As seen in the non-zero scores, S4 and S5 were easier this year. CCC 2019 CCC 2020 Due to an easier S4 and S5, the 2020 CCO cut-off is 57 and 25 contestants have been invited. In comparison, last year‚Äôs cut-off was 48 and 31 were invited.This year‚Äôs Honour Roll cut-off of 37, down from last year‚Äôs 39.Problem AnalysisS1: Surmising a Sprinter‚Äôs SpeedSolution: sort the points by time. Then, loop over consecutive pairs to find the constant speed in each interval. The answer is the maximum of the speeds.Time complexity: $\\mathcal{O}(N \\log(N))$.S2: Escape RoomSolution: Perform a depth-first search (DFS) on the cells. There are $N \\cdot M$ cells and individually finding the factors of each number has complexity $\\mathcal{O}(\\sqrt{\\text{max_cell_number}})$. This results is a loose upper bound of $NM \\cdot \\sqrt{\\text{max_cell_number}} = 10^3 \\cdot 10^3 \\cdot \\sqrt{10^6} = 10^9$ operations. Although it appears that this solution cuts close to the time limit, it can pass.For a faster solution, observe that when the cell at $(i, j)$ has value $v$, a cell of product $i \\cdot j$ can reach a cell of product $v$. Let us add an edge from node $i \\cdot j$ to node $v$. The answer is ‚Äúyes‚Äù iff there exists a path from node $1$ to node $n \\cdot m$.Time complexity: $\\mathcal{O}(NM)$ or $\\mathcal{O}(NM \\sqrt{ \\text{max_cell_number} })$.S3: Searching for StringsLet $S$ be a substring of $H$ with length $|N|$. To check whether $S$ is a permutation of $N$, keep a count of each of the 26 letters of the alphabet. If the counts of $S$ and $N$ all match, then they are permutations of each other. To do this quickly, loop through the $S$s from left to right. This way, at most two characters are added or removed each time we shift right by one character. This lets us know which substrings can satisfy the ‚Äúpermutation‚Äù requirement.Now we will find the number of distinct subtrings $S$ that work. Let $T$ be the set of all such $S$. To eliminate duplicates, we need a quick way of comparing the elements of $T$. This can be done quickly by using a rolling hash. We insert valid $\\text{hash}(S)$s into set $T$. Finally, the answer is the cardinality of $T$.Time complexity: $\\mathcal{O}(|H|)$ or $\\mathcal{O}(|H| \\log(|H|))$.S4: Swapping SeatsFirst, let us solve the problem where the $1^{st}$ person and $N^{th}$ person are not adjacent. After all our swaps, segments of $A$, $B$, and $C$ type people will be contiguous. The order that these segments appear in is a permutation of $ABC$ (e.g. $ABC$, $ACB$, $BAC$, ‚Ä¶). We can try all 6 permutations. In each permutation, the table is split into 3 segments that will eventually be occupied $A/B/C$ people. Let‚Äôs call these ‚Äúfinal groups‚Äù. If a person of group $X$ is already in the final group of $X$, there is no point in moving him. If an $X$ and a $Y$ person can end up in their correct final groups by swapping the two, swap them. Otherwise, we will have a non-negative number of triples of three people‚Äîone from each group‚Äîwho can all end up where they need to be in $2$ swaps (this looks like shifting $(X, Y, Z)$ to $(Y, Z, X)$). This algorithm is guaranteed to give the minimum number of swaps needed. Notice that all we care about is which group each person is from and which $A/B/C$ final segment he is currently in. If we go back to the circular case and everyone shifts left by one seat, only three people will be in different final groups. Thus, we can shift the table $N$ times and check the required swap-count each time. The answer is the minimum of the swap-counts.Time complexity: $\\mathcal{O}(N)$.S5: Josh‚Äôs Double Bacon DeluxeLet $P_i$ be the probability that John does not get his burger if the $i^{th}$ person does not get his burger. The base case is $P_N = 0$. For all $i$, $ i\\neq 1$, if $b_i = b_1$, $i$ will take the coach‚Äôs burger and everyone after $i$ gets the correct burger. Otherwise, if there exists a person $j$ after $i$ who ordered the same burger as person $i$, person $i$ will take person $j$‚Äôs burger. In this case, $P_i = P_j$. Otherwise, $i$ will take a remaining burger at random. If $i$ takes the coach‚Äôs burger, then everyone behind $i$ will get his own burger. Otherwise, if $i$ takes $j$‚Äôs burger, then the probability in this case is $P_j$. Here, $P_i = \\frac{1 + \\sum_{j = i+1}^{n} {P_j}}{n-i+1}$. We can also use this recurrence to calculate $P_1$, which is our final answer.\\[P_i=\\begin{cases}\t\t0&amp; \\text{if } i = N\\\\\t\t1&amp; \\text{if } i \\neq 1, b_i = b_1\\\\\t\tP_j&amp; \\text{if } i \\neq 1, \\exists \\,\\, j \\, | \\, j &gt; i, b_j = b_i\\\\\t\t\\frac{1 + \\sum_{j = i+1}^{n} {P_j}}{n-i+1}&amp; \\text{otherwise}\t\\end{cases}\\]Finding whether there exists a $j$ for a given $i$ can be done in $\\mathcal{O}(1)$ many different ways. Finding the suffix sums of $P$ can be done in $\\mathcal{O}(1)$ each time if we find $P_i$s in decreasing order of $i$.Time complexity: $\\mathcal{O}(N)$.SummaryI enjoyed solving this year‚Äôs CCC problems and I hope that you enjoy them as well. My solutions in C++ are available here and at the bottom of the page.My Solutions in C++S1// S1 solution in O(N log N)#include &lt;bits/stdc++.h&gt;using namespace std;pair&lt;double, double&gt; a[100005];int n;double ans;int main(){\tios_base::sync_with_stdio(0);\tcin.tie(0);\tcin&gt;&gt;n;\tfor(int i = 0; i &lt; n; i++)\t\tcin&gt;&gt;a[i].first&gt;&gt;a[i].second;\tsort(a, a+n);\tfor(int i = 1; i &lt; n; i++){\t\tans = max(ans, abs(a[i].second-a[i-1].second)/(a[i].first-a[i-1].first));\t}\tcout&lt;&lt;fixed&lt;&lt;setprecision(9)&lt;&lt;ans&lt;&lt;'\\n';}S2// S2 solution in O(NM)#include &lt;bits/stdc++.h&gt;using namespace std;constexpr int MM = 1e6+5;int n, m;bool vis[MM];vector&lt;int&gt; adj[MM];void go(int u){\tif(u == n){\t\tcout&lt;&lt;\"yes\\n\";\t\texit(0);\t}\tvis[u] = 1;\tfor(int i: adj[u])\t\tif(!vis[i])\t\t\tgo(i);}int main(){\tios_base::sync_with_stdio(0);\tcin.tie(0);\tcin&gt;&gt;n&gt;&gt;m;\tfor(int i = 1,k; i &lt;= n; i++){\t\tk = i;\t\tfor(int j = 1,v; j &lt;= m; j++, k += i){\t\t\tcin&gt;&gt;v;\t\t\tadj[k].emplace_back(v);\t\t}\t}\tn *= m;\tgo(1);\tcout&lt;&lt;\"no\\n\";}S3// S3 solution in O(|H| log |H|)#include &lt;bits/stdc++.h&gt;using namespace std;using ll = long long;constexpr int MM = 2e5+5;int n, m, cnta[30], cntb[30];char sa[MM], sb[MM];set&lt;pair&lt;ll, ll&gt;&gt; st;ll base = 131, mod = 1685518853;ll base2 = 131, mod2 = 1494318097;ll h[MM], p[MM], h2[MM], p2[MM];void go(int j){\tfor(int i = 0; i &lt; 30; i++)\t\tif(cnta[i] != cntb[i])\t\t\treturn;\tll hs = ((h[j] - h[j-n]*p[n])%mod+mod)%mod;\tll hs2 = ((h2[j] - h2[j-n]*p2[n])%mod2+mod2)%mod2;\tst.insert({hs, hs2});}int main(){\tscanf(\"%s %s\", sa+1, sb+1);\tn = strlen(sa+1), m = strlen(sb+1);\tp[0] = p2[0] = 1;\tfor(int i = 1; i &lt;= m; i++){\t\tp[i] = p[i-1]*base%mod;\t\th[i] = (h[i-1]*base + sb[i])%mod;\t\tp2[i] = p2[i-1]*base2%mod2;\t\th2[i] = (h2[i-1]*base2 + sb[i])%mod2;\t}\tfor(int i = 1; i &lt;= n; i++){\t\tcnta[sa[i]-'a']++;\t\tcntb[sb[i]-'a']++;\t}\tgo(n);\tfor(int i = n+1; i &lt;= m; i++){\t\tcntb[sb[i]-'a']++;\t\tcntb[sb[i-n]-'a']--;\t\tgo(i);\t}\tprintf(\"%ld\\n\", st.size());}S4// S4 solution in O(N)#include &lt;bits/stdc++.h&gt;using namespace std;constexpr int MM = 1e6+2;int n, cnt[3][3], ans = 1e9, num[3], na, nb, nc;char s[MM], ins[MM];int aa[] = {0, 1, 2};void go(){\tint tot = n-cnt[0][0]-cnt[1][1]-cnt[2][2], res = 0;\tfor(int i = 0; i &lt; 3; i++){\t\tfor(int j = 0; j &lt; i; j++){\t\t\tint sub = min(cnt[i][j], cnt[j][i]);\t\t\tres += sub;\t\t\ttot -= sub*2;\t\t}\t}\tassert(tot % 3 == 0);\tres += tot/3*2;\tans = min(ans, res);}void run(){\tmemset(num, 0, sizeof num);\tmemset(cnt, 0, sizeof cnt);\tfor(int i = 0; i &lt; n; i++){\t\ts[i] = aa[ins[i]];\t\tnum[s[i]]++;\t}\tna = num[0], nb = num[1], nc = num[2];\tauto gp = [](int i){\t\tif(i &lt; na)\t\t\treturn 0;\t\tif(i &lt; na+nb)\t\t\treturn 1;\t\treturn 2;\t};\tfor(int i = 0; i &lt; n; i++)\t\tcnt[gp(i)][s[i]]++;\tgo();\tauto at = [](int i){\t\ti %= n;\t\tif(i &lt; 0) i += n;\t\treturn i;\t};\tfor(int sh = 0; sh &lt;= n; sh++){\t\tcnt[0][s[at(na-1-sh)]]--;\t\tcnt[1][s[at(na-1-sh)]]++;\t\t\t\tcnt[1][s[at(na+nb-1-sh)]]--;\t\tcnt[2][s[at(na+nb-1-sh)]]++;\t\t\t\tcnt[2][s[at(n-1-sh)]]--;\t\tcnt[0][s[at(n-1-sh)]]++;\t\tgo();\t}}int main(){\tscanf(\"%s\", s);\tn = strlen(s);\tfor(int i = 0; i &lt; n; i++){\t\ts[i] -= 'A';\t\tins[i] = s[i];\t}\tdo{\t\trun();\t} while(next_permutation(aa, aa+3));\t\tprintf(\"%d\\n\", ans);}S5// S5 solution in O(N log N)#include &lt;bits/stdc++.h&gt;using namespace std;constexpr int MM = 1e6+2;int n, a[MM];map&lt;int, int&gt; mp;double dp[MM], suf;int main(){\tscanf(\"%d\", &amp;n);\tfor(int i = 1; i &lt;= n; i++)\t\tscanf(\"%d\", a+i);\t\tif(a[1] == a[n])\t\treturn printf(\"1\\n\"), 0;\tmp[a[n]] = n;\t\tfor(int i = n-1; i &gt; 1; i--){\t\tif(a[i] == a[1]){\t\t\tdp[i] = 1;\t\t\tmp[a[i]] = i;\t\t}\t\telse if(mp[a[i]])\t\t\tdp[i] = dp[mp[a[i]]];\t\telse\t\t\tdp[i] = (suf+1)/(n-i+1);\t\t\t\tmp[a[i]] = i;\t\tsuf += dp[i];\t}\t\tprintf(\"%.8lf\\n\", accumulate(dp+2, dp+n, 1.0)/n);}" } ]
